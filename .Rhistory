topfeatures(c('sdf','sdf','afa'))
require(quanteda, quietly=TRUE)
require(dplyr, quietly=TRUE)
## Compile populism-word dictionary from 'Appendix B' of Rooduijin, et al. (2011)
pop.dict <- dictionary(list(Core = c('elit*', 'consensus*', 'undemocratic*', 'referend*', 'corrupt*', 'propagand*', 'politici*', '*deceit*', '*deceiv*', '*betray*', 'shame*', 'scandal*', 'truth*', 'dishonest*'),
Context = c('establishm*', 'ruling*')))
## Create document-feature matrix for occurrences of 'populist' words in corpus
pop.dfm <- dfm(ie2010Corpus, groups='party', dictionary = pop.dict)
pop.mat <- as.matrix(pop.dfm)
pop.mat
substring("asdf", 3)
lexdiv
inaugTexts
str(inaugCorpus)
summary(inaugCorpus, n=5)
lm
ls
ls()
rm(mtcars)
rm(Expo, g4, difference, ToothGrowth, theory)
ls()
rm(g6)
ex
dfm(ex)
summary(dfm(ex))
test)
test
koquant
lexdiv(koquant)
summary(pop.dfm)
popdfm
pop.dfm
lexdiv(pop.dfm)
party.dfm <- dfm(ie2010Corpus, groups='party')
default.dfm <- dfm(ie2010Corpus)
default.dfmm
default.dfm
default.dfm(n=5)
summary(default.dfm)
summary(default.dfm, n=5)
default.dfm[, 1:4]
party.dfm[,1:4]
lexdiv(party.dfm)
quanteda
??read
getwd()
ls()
typeof(a)
a
a <- textfile('constitution.txt')
class(a)
corpus.a <- corpus(a)
corpus.a
summary(corpus.a))
summary(corpus.a)
const.dfm <- dfm(a)
const.dfm <- dfm(corpus.a)
dfm(ex)
const.dfm[,1:10]
a <- textfile('constitution.txt')
summary(corpus.a)
const.dfm <- dfm(corpus(a))
const.dfm[,1:14]
t(const.dfm[,1:14])
const.dfm[,1:14]
rownames(const.dfm[,1:14])
colnames(const.dfm[,1:14])
a <- textfile('constitution.txt') ## text was saved with UTF 8 encoding
const.dfm <- dfm(corpus(a))
const.dfm[,1:14]
summary(const.dfm)
b <- read.file('constitution.txt')
?read.file
b <- read.table('constitution.txt')
?read.text
b <- read.table('constitution.txt', sep = '\n')
?readLines
b <- readLines('constitution.txt')
class(b)
b
length(b)
sys.getlocale
Sys.getlocale()
Sys.setlocale("LC_COLLATE", 'ko_KR.UTF-8')
Sys.getlocale()
'그냥'
Encoding()
Encoding() <- 'unknown'
ex
b <- read.table('constitution.txt')
b
b <- read.table('constitution.txt', encoding='utf8')
b[1:3]
b <- read.table('constitution.txt', encoding='UTF-8')
b[1:3]
?read.table
b <- read.table('constitution.txt', fileEncoding='UTF-8', encoding = 'unknown')
b
b <- read.table('constitution.txt', fileEncoding='UTF8', encoding = 'unknown')
?readLines
b <- readLines('constitution.txt', encoding = 'unknown')
length(b)
b[1]
print(b[1])
nat <- parse(text=b[1])
nat
nat <- parse(text=paste("'", b[1], "'")
)
localeToCharset(locale = Sys.getlocale())
Sys.getlocale()
setlocale(LC_ALL, 'Korean')
b <- read.table('constitution.txt', encoding = 'UTF-8')
b[1]
iconv()
Sys.getlocale()
localeToCharset()
Sys.setlocale(cateogry= "LC_ALL", locale ='en_us.UTF-8')
Sys.setlocale(category= "LC_ALL", locale ='en_us.UTF-8')
Encoding(sente)
Encoding(sent)
sent <- "R 미쳐버리겠다 너"
Encoding(sent)
localeToCharset()
localeToCharset()[1]
iconv(sent, localeToCharset()[1], 'UTF-8')
?iconv
b <- read.table('constitution.txt', encoding = 'UTF-8')
b <- readLines('constitution.txt', encoding = 'UTF-8')
Encoding(b)
bconv <- iconv(b, localeToCharset()[1], 'UTF-8')
bconv[1]
bconv[1:4
]
bconv[1:10]
b <- readLines('constitution.txt')
bconv <- iconv(b, localeToCharset()[1], 'UTF-8')
bconv[1:15]
Encoding(b)
Encoding(b) <- 'UTF-8'
Encoding(b)
b[1:14]
?textfile
const <- textfile('constitution.txt') ## text was saved with UTF 8 encoding
Encoding(const)
const
const[1]
summary(const)
summary(const, n=5
)
tokenize(const)
tokenize(b)
convertHangulStringtoJamos('우하하')
require(KoNLP)
convertHangulStringtoJamos('우하하')
convertHangulStringToJamos('우하하')
convertHangulStringToKeyStrokes('우하하')
SimplePos09('미친놈이 아니고서야 그렇게 받아들일 수 없다')
extractNoun('이대로 죽을순없잖아.살려주세요 김미경씨. 대한민국을 위해서? 박정희대통령 ㄷ통령 박정희')
SimplePos09('미친놈이 아니고서야 그렇게 받아들일 수 없다')
posex <- SimplePos09('미친놈이 아니고서야 그렇게 받아들일 수 없다')
class(posex)
posex[1]
posex[1][1]
posex[['미친놈이']]
posex[['미친놈이']][1]
tokenize(const)
tokenize('I am going to the supermarket sir')
sys.getlocale()
Sys.getlocale()
Sys.setlocale("LC_ALL", 'en_GB.UTF-8')
Sys.setlocale("LC_ALL", "en_GB.UTF-8")
?setlocale
?Sys.setlocale
Sys.setlocale(category = "LC_ALL", locale ="en_GB.UTF-8")
Sys.getlocale()
Sys.setlocale('LC_ALL', 'C')
president <- read.csv('D://dropbox/Dropbox/ME114_n/prescrapes/presidents_1-315.csv', header=T, quote = '"', sep= ',', stringsAsFactors = F, encoding='UTF-8')
Sys.setlocale('LC_ALL', 'Korean_Korea.949')
president.pos <- lapply(president$text[1:3], extractNoun)
require(quanteda)
require(KoNLP)
require(quanteda)
president.pos <- lapply(president$text[1:3], extractNoun)
sapply(president$text[1:3], extractNoun)
president.sap <- sapply(president$text[1:3], extractNoun)
president.sap
dim(president.sap
)
class(president.sap)
rm(president.sap)
data.frame(president.pos)
rbind(president.pos)
cbind(president.pos)
presr <- rbind(president.pos)
presr
dim(presr)
presr[1,1]
str(presr)
presr
View(presr)
president.pos <- rbind(president.pos)
president.pos <- lapply(president$text[1:3], extractNoun)
president.pos <- rbind(president.pos)
do.call(paste, president.pos)
president.pos <- cbind(president.pos)
presidnet.pos
president.pos
do.call(paste, president.pos)
president.pos <- rbind(president.pos)
president.pos <- lapply(president$text[1:3], extractNoun)
president.pos <- rbind(president.pos)
apply(president.pos, 1, paste)
apply(president.pos, 1, paste(paste))
apply(president.pos, 1, paste(paste()))
president.pos
apply(president.pos, 2, paste)
president.pos <- lapply(president$text[1:3], extractNoun)
do.call(paste, president.pos)
T(president.pos)
?transpose
t(president.pos)
do.call(paste, t(president.pos))
president.pos <- lapply(president$text[1:3], extractNoun)
do.call(rbind, president.pos)
president.pos <- lapply(president$text[1:3], extractNoun)
president.pos <- do.call(rbind, president.pos)
president.pos <- do.call(rbind, president.pos)
president.pos <- do.call(rbind, president.pos)
president.pos <- lapply(president$text[1:3], extractNoun)
president.pos <- do.call(rbind, president.pos)
str(president.pos)
dim(president.pos)
class(president.pos)
apply(president.pos, 1, paste)
apply(president.pos, 2, paste)
president.pos[1,]
paste(president.pos[1,])
do.call(paste, president.pos[1,])
do.call(paste, as.list(president.pos[1,]))
apply(president.pos, 1, function(x) do.call(paste, as.list(x[1,])))
president.pos <- lapply(president$text[1:3], extractNoun)
president.pos <- do.call(rbind, president.pos)
president.pos <- data.frame(president.pos)
apply(president.pos, 1, function(x) do.call(paste, as.list(x[1,])))
?apply
president.pos[1,]
president.pos <- do.call(rbind, president.pos)
president.pos <- lapply(president$text[1:3], extractNoun)
president.pos <- do.call(rbind, president.pos)
apply(president.pos, 1, function(x) do.call(paste, as.list(x)))
president.pos <- lapply(president$text[1:3], extractNoun)
president.pos <- rbind(president.pos)
apply(president.pos, 1, function(x) do.call(paste, as.list(x)))
president.pos <- lapply(president$text[1:3], extractNoun)
president.pos <- do.call(rbind, president.pos)
apply(president.pos, 1, function(x) do.call(paste, as.list(x)))
president.pos <- lapply(president$text[1:50], extractNoun)
president.pos <- do.call(rbind, president.pos)
president.pos <- apply(president.pos, 1, function(x) do.call(paste, as.list(x)))
View(president.pos)
str(president.pos)
president.corpus <- corpus(president.pos)
docvars(president.corpus, 'President') <- president$name
docvars(president.corpus, 'Date') <- president$type
president.dfm <- dfm(president.corpus)
lexdiv(president.dfm)
plot(president.dfm)
lexdiv(president.dfm)
plot(lexdiv(president.dfm))
topfeatures(president.dfm)
max(lexdiv(president.dfm))
index(max(lexdiv(president.dfm)))
which(max(lexdiv(president.dfm)))
which(max(lexdiv(president.dfm))==lexdiv(president.dfm))
president.dfm$text[45]
?dfm
president.dfm[45,]
president.dfm[1:3,]
president.dfm[1:3,1:19]
president.dfm[45,1:19]
president.dfm[43:46,1:19]
topfeatures(president.dfm[45, ])
extractNoun('유의하시기 바랍니다')
extractNoun('유의하시기 박정희트랙터 바랍니다')
extractNoun('유의하시기 박정희는 트랙터 바랍니다')
docvars(president.corpus, 'President') <- president$name1[1:50]
president.dfm <- dfm(president.corpus)
president.dfm[1:3,1:5]
president.pos <- lapply(president$text, extractNoun)
president.pos <- lapply(president$text[2000:3000], extractNoun)
Sys.setlocale('LC_ALL', 'C')
president <- read.csv('D://dropbox/Dropbox/ME114_n/prescrapes/presidents_1-315.csv', header=T, quote = '"', sep= ',', stringsAsFactors = F, encoding='UTF-8')
Sys.setlocale('LC_ALL', 'Korean_Korea.949')
require(quanteda)
require(KoNLP)
# 여기에 이제 president$text 대신에 내가 빼냈던 KONLP 자료들을 넣어주는거지
## 여기 밑에 있는 건 benoit 보여주는 차원에서는 괜찮겠다.
president.pos <- lapply(president$text[2000:3000], extractNoun)
president.pos <- do.call(rbind, president.pos)
president.pos <- apply(president.pos, 1, function(x) do.call(paste, as.list(x)))
president.corpus <- corpus(president.pos)
docvars(president.corpus, 'President') <- president$name1[2000:3000]
docvars(president.corpus, 'Date') <- president$date[2000:3000]
president.corpus
summary(president.corpus, n=5)
class(president$date[1])
as.Date.character('1973.03.07')
as.Date('1973.03.07')
as.Date.numeric('1973.03.07')
?as.Date
as.Date.numeric('1973-03-07')
as.Date('1973-03-07')
class(as.Date('1973-03-07'))
as.Date('1973-03-07')+1
as.Date('1973-03-07')<1
president$date[1:200]
president$date[1000:1500]
docvars(president.corpus, 'Date') <- substring(president$date[2000:3000], 1, 4)
summary(president.corpus, n=5)
docvars(president.corpus, 'Year') <- as.integer(substring(president$date[2000:3000], 1, 4))
president.dfm <- dfm(president.corpus)
plot(lexdiv(president.dfm))
president.dfm[1:3,1:10]
president.dfm[1:3,1:5]
president.dfm[1:3,5:10]
president.dfm[3:10,5:10]
president.dfm[3:10,1:5]
president.pos[1,]
president.pos[,1]
president.pos[1]
president.pos[2]
?iconv
txtfile <- textfile('D://dropbox/Dropbox/quanteda/kr_president.csv', textField = 'text')
Sys.setlocale('LC_ALL', 'Korean_Korea.949') ## change to Korean Windows machine default (Which is my setting)
txtfile <- textfile('D://dropbox/Dropbox/quanteda/kr_president.csv', textField = 'text')
Sys.setlocale('LC_ALL', "C")
txtfile <- textfile('D://dropbox/Dropbox/quanteda/kr_president.csv', textField = 'text')
textfilecorpus <- corpus(txtfile)
textfiledoc <- textfilecorpus$documents ## Unfortunately, the result is raw unicode
textfiledoc
textfiledoc[1]
iconv(textfiledoc[1], 'UTF-8', 'cp949')
iconv(textfiledoc[1], 'UTF-8', 'CP949')
iconv(textfiledoc[1], from ='UTF-8', to ='cp949')
iconv(textfilecorpus, from ='UTF-8', to ='cp949')
require(quanteda)
tokenize('나의 나라')
SimplePos09('나의 나라') ## simple POS tagging
extractNoun('나의 나라') ## noun extraction
require(KoNLP)
SimplePos09('나의 나라') ## simple POS tagging
extractNoun('나의 나라') ## noun extraction
install.packages('stringi')
install.packages("stringi")
install.packages("stringi")
install.packages("stringi")
install.packages("stringi")
?stringi
uword('나는 아니다')
stri_opts_regex('ㄴ어래ㅓ')
library(stringi)
stri_opts_regex('ㄴ어래ㅓ')
stri_opts_regex('ㄴ어래ㅓ', uword = 'T')
stri_opts_regex('ㄴ어래ㅓ', uword = TRUE)
stri_opts_regex('ㄴ어래ㅓ', uword = 'TRUE')
stri_opts_regex('ㄴ어래ㅓ', uword)
stri_opts_regex('나는 가방에 드렁간다')
stri_opts_regex('you give m something')
stri_extract_all_boundaries('나는 죽었다')
stri_extract_all_boundaries('given some of the things youdid')
?locale
stri_locale_list
stri_locale_list()
stri_extract_all_boundaries('given some of the things youdid', locale='ko')
stri_extract_all_boundaries('니먼 랩에서 하는 거랍니다', locale='ko')
?stri_extract_all_boundaries
stri_extract_all_words('니먼 랩에서 하는 거랍니다', locale='ko')
stri_extract_all_words('니먼 랩에서 하는 거라고는 하는데다', locale='ko')
stri_extract_all_words('니먼 랩에서 하는 거라고는 하는데다', locale='ko_kp')
stri_extract_all_words('니먼 랩에서 하는 거라고는 하는데다')
stri_locale_list()
stri_extract_all_words('니먼 랩에서 하는 거라고는 하는데다', locale='ko_KR')
stri_extract_all_boundaries('니먼 랩에서 하는 거랍니다', locale='ko_KR')
stri_extract_all_boundaries('니먼 랩에서 하는 거랍니다', locale='ko_KP')
stri_locate_all_boundaries('랩에서 한다는데도')
?stri_locate_all_boundaries()
stri_locale_get()
Sys.getlocale()
stri_locate_all_boundaries('랩에서 한다는데도', locale='ko')
stri_extract_all_boundaries('랩에서 한다는데도', locale='ko')
tokenize('나의 나라')
require(quanteda)
tokenize('나의 나라에서는 있을 수 없는 일')
tokenize('I am the king of the world wordly worded')
lemmatize()
lemma()
require(KoNLP)
SimplePos09('나의 나라에서는 있을 수 없는 일이 일어났다')
SimplePos09('그는 Chicago로 갔다')
SimplePos09('그는 Chicago로 간다')
SimplePos09('그는 Chicago로 죽인다')
SimplePos09('그는 Chicago로 죽는다')
SimplePos09('그는 Chicago로 죽었다')
tokenize('나의,그리고 그의.사랑')
tokenize('나의그리고 그의 사랑')
tokenize('나는 아니다')
tokenize('나의 나라')
Sys.getlocale()
Sys.setlocale()
Sys.setlocale ('LC_ALL', 'Ko')
locale in Korean
Sys.setlocale('LC_ALL', 'ko_KR.UTF-8')
Sys.setlocale('LC_ALL', 'C')
tokenize('나의 나라')
Sys.setlocale('LC_ALL', 'Korean_Korea.949') ## replicates my setting
tokenize('나의 나라')
detach("package:stringi", unload=TRUE)
library("stringi", lib.loc="C:/Program Files/R/R-3.2.1/library")
stri_locale_list
stri_locale_list()
stri_extract_all_boundaries('랩에서 한다는데도', locale='ko')
stri_extract_all_boundaries('나는 Chicago에 산다', locale='ko')
stri_extract_all_boundaries('나는 Chicago에 산다', locale='ko_KR')
stri_extract_all_words('나는 Chicago에 산다', locale='ko_KR')
stri_extract_all_boundaries('나는 Chicago에 산다고 말할수도 있고 아니라고 말할 수도 있습니다', locale='ko_KR')
tokenize('Saunauntensitzer')
tokenize('Saunauntensitzer', locale = german)
?tokenize
?tokenize
tokenize('Saunauntensitzer', ngrams = 3)
tokenize('Saunauntensitzer', ngrams = 2)
library(caret)
install.packages('caret')
install.packages('grid')
library(grid)
grid
Q <- as.matrix(read.csv("Q.csv", header=FALSE))
install.packages()
install.packages('wnominate')
library(pscl)
library(wnominate)
library(foreign)
library(gdata)
install.packages('gdata')
library(gdata)
data.txt <- read.delim("D://dropbox/Dropbox/scraping/1_NA/NOMINATE/un3133.txt")
colnames(data.txt)						# Note the first three columns aren't votes
dim(data.txt)
class(data.txt)
head(data.txt)
rc.txt <- rollcall(data.txt[,-(1:3)], yea=1, nay=6,		# Format data as rollcall object
missing=9,
notInLegis=0,
legis.names=data.txt[,3],
desc="UN 31 to 33",
vote.names=colnames(data.txt)[-(1:3)])
rc.txt
result <- wnominate(rc.txt, dims=2, polarity=c(1,2))	#Run wnominate on rollcall object
summary(result)						#summarize results
windows()
plot(result)
plot(result)
windows()
plot(result)
result$legislators
?write.fwf
original <- read.table('household_power_consumption.txt', sep=';', header = T)
## We will only be using data from the dates 2007-02-01 and 2007-02-02.
## One alternative is to read the data from just those dates rather than
## reading in the entire dataset and subsetting to those dates.
# strptime, as.Date() functions!
original$Date <- as.Date(original$Date, '%d/%m/%Y')
original$Time <- strptime(original$Time, '%T')
febone <- unclass(as.Date('2007-02-01'))
febsec <- unclass(as.Date('2007-02-02'))
filtered<- subset(original, unclass(original$Date) %in% c(febone,febsec)) # subset the two dates
x <- as.numeric(as.vector(filtered$Global_active_power)) # because Global Active Power is in Factor form,
# convert to vector and then to numeric
setwd("D://dropbox/Dropbox/git/")
setwd('ExData_Plotting1')
original <- read.table('household_power_consumption.txt', sep=';', header = T)
## We will only be using data from the dates 2007-02-01 and 2007-02-02.
## One alternative is to read the data from just those dates rather than
## reading in the entire dataset and subsetting to those dates.
# strptime, as.Date() functions!
original$Date <- as.Date(original$Date, '%d/%m/%Y')
original$Time <- strptime(original$Time, '%T')
febone <- unclass(as.Date('2007-02-01'))
febsec <- unclass(as.Date('2007-02-02'))
filtered<- subset(original, unclass(original$Date) %in% c(febone,febsec)) # subset the two dates
x <- as.numeric(as.vector(filtered$Global_active_power)) # because Global Active Power is in Factor form,
class(x)
length(x)
png(file = 'plot1.png', width = 480, height = 480)
par(fin = c(480*1/96, 480*1/96), mar = c(4,3,3,2)) # par accepts inches - 1/96 inch = 1 pixel
hist(x, xlab = "Global Active Power (kilowatts)", ylab = "Frequency",
main = "Global Active Power", col = "red", yaxs = 'r')
dev.off()
origins <- fread('household_power_consumption.txt')
require(data.table)
require(data.table)
origins <- fread('household_power_consumption.txt')
head(origins)
class(origins$Time)
original$Date[0:20]
class(original$Date)
class(origins$Date)
?as.Date
DT[, mean(pwgtp15), by = SEX]
origins[ , as.date(Date)]
origins[ , as.Date(Date)]
head(origins)
